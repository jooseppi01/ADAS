{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmmvUTQmkFsw"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import paho.mqtt.client as mqtt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdfffCGT354i"
      },
      "outputs": [],
      "source": [
        "#!pip install paho-mqtt\n",
        "# Load the model\n",
        "model = tf.keras.models.load_model(\"cnn12-2.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsNwkHVzpX39"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufzN36RdkN6g"
      },
      "outputs": [],
      "source": [
        "### TODO: Paste IoU function here\n",
        "def IoU(box_predicted, box_true, verbose = True):\n",
        "    (x1_pred, y1_pred, x2_pred, y2_pred) = box_predicted\n",
        "    (x1_true, y1_true, x2_true, y2_true) = box_true\n",
        "\n",
        "    # calculate intersection area\n",
        "    xx1 = np.maximum(x1_pred, x1_true)\n",
        "    yy1 = np.maximum(y1_pred, y1_true)\n",
        "    xx2 = np.minimum(x2_pred, x2_true)\n",
        "    yy2 = np.minimum(y2_pred, y2_true)\n",
        "\n",
        "    w = np.maximum(0, xx2 - xx1 + 1)\n",
        "    h = np.maximum(0, yy2 - yy1 + 1)\n",
        "    intersectionArea = w * h\n",
        "\n",
        "    if verbose:\n",
        "        print(\"w:\", w)\n",
        "        print(\"h:\", h)\n",
        "        print(\"Intersection area:\", intersectionArea)\n",
        "\n",
        "    # calculate the areas for the prediction and ground-truth (true) boxes\n",
        "    boxPredictedArea = (x2_pred - x1_pred + 1) * (y2_pred - y1_pred + 1)\n",
        "    boxTrueArea = (x2_true - x1_true + 1) * (y2_true - y1_true + 1)\n",
        "\n",
        "    # calculate the union area\n",
        "    unionArea = boxPredictedArea + boxTrueArea - intersectionArea\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Union area:\", unionArea)\n",
        "\n",
        "    # return IoU\n",
        "    return intersectionArea / float(unionArea)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "669xEUEfkTvb"
      },
      "outputs": [],
      "source": [
        "def NMS(boxes, probs, threshold=0.5, verbose=False):# to remove the rectangles\n",
        "    D_index = []\n",
        "\n",
        "    # sort indexes by probability\n",
        "    B_index = np.argsort(probs)\n",
        "\n",
        "    # keep looping while some indexes still remain in the indexes list\n",
        "    while len(B_index) > 0:\n",
        "        # append the index of the rectangle with the highest probability to D\n",
        "        last = len(B_index) - 1\n",
        "        d_index = B_index[last]\n",
        "        D_index.append(d_index)\n",
        "        B_index = np.delete(B_index, [last]) # delete the index from index list B\n",
        "\n",
        "        overlaps=[]\n",
        "        for b_index in B_index[:last]: #\n",
        "            b = boxes[b_index]\n",
        "            d = boxes[d_index]\n",
        "            ### TODO: Calculate the overlap between the two boxes\n",
        "            overlap = IoU(b, d, verbose=verbose)\n",
        "            ### TODO: Append overlap to list overlaps\n",
        "            overlaps.append(overlap)\n",
        "\n",
        "        overlaps = np.asarray(overlaps) # convert to array, necessary for comparison below (np.where(overlaps > threshold))\n",
        "\n",
        "        # delete candidate rectangles (indexes) from B who overlap greather than the threshold hyper parameter\n",
        "        indexes_to_delete = np.where(overlaps > threshold)\n",
        "        ### TODO: Remove the indexes 'indexes_to_delete' from index list B\n",
        "        B_index = np.delete(B_index, indexes_to_delete[0])\n",
        "\n",
        "    return D_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTHuXVfMkFs0"
      },
      "outputs": [],
      "source": [
        "def read_img(path, ratio=.1):\n",
        "  \"\"\"\n",
        "      Function to read an image from path (the image received from the App\n",
        "      will be saved and then read again using this function)\n",
        "  \"\"\"\n",
        "  img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "  if img.size > 1000000:\n",
        "     img = cv2.resize(img, (0,0), fx=ratio, fy=ratio)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "670cfDPHkFs2"
      },
      "outputs": [],
      "source": [
        "def create_selective_regions(img):\n",
        "  \"\"\"\n",
        "      Create Regions from img: takes random regions \"Boxes\" from the image\n",
        "  \"\"\"\n",
        "  ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation() # selective search\n",
        "  ss.setBaseImage(img)\n",
        "  ss.switchToSelectiveSearchFast()\n",
        "  rects = ss.process()\n",
        "  print(\"Number of found rectangles: \" + str(len(rects)))\n",
        "  return rects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "matho3N0kFs3"
      },
      "outputs": [],
      "source": [
        "def create_mini_images(img, rects):\n",
        "  \"\"\"\n",
        "      Transform the rectangles (the coordinates x,y,w,h) into small images\n",
        "  \"\"\"\n",
        "  imgs = []\n",
        "  for (startX, startY, width, height) in rects: # iterate through all interesting regions\n",
        "      imgs.append(img[startY:(startY + height), startX:(startX + width)]) # extract the interesting region from the image, add\n",
        "  return imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWxWOn3gmi3r"
      },
      "outputs": [],
      "source": [
        "def preprocess_imgs(imgs, inputsize):\n",
        "    \"\"\"\n",
        "        Resize the images and normalize (transform the values to a range 0,1)\n",
        "    \"\"\"\n",
        "    for i in range(len(imgs)):\n",
        "        # resize it to the required input dimensions of our trained CNN\n",
        "        imgs[i] = cv2.resize(imgs[i], inputsize, interpolation=cv2.INTER_CUBIC)\n",
        "        # normalize the pixel values\n",
        "        imgs[i] = imgs[i] * 1./255\n",
        "    return imgs\n",
        "\n",
        "def prob_and_label_multiple_imgs(imgs, inputsize = (56, 56)):\n",
        "    \"\"\"\n",
        "        Feed the images to the model and get the classes and probabilities\n",
        "    \"\"\"\n",
        "    print(\"\\nDetecting the class of each region:\")\n",
        "    (H, W) = inputsize\n",
        "    imgs = preprocess_imgs(imgs, inputsize)\n",
        "    imgs = np.resize(imgs, (len(imgs), H, W, 3)) # array size: number of images(len(imgs))x56x56x3(RGB)\n",
        "    preds = model.predict(imgs)\n",
        "    print(\"Done!\\n\")\n",
        "    probs = np.max(preds, axis=-1)\n",
        "    labels = np.argmax(preds, axis=-1)\n",
        "    return (probs, labels)\n",
        "\n",
        "\n",
        "################################################################\n",
        "##    The result here will be classes and its propabilities   ##\n",
        "################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eTJUPQOuWlm"
      },
      "outputs": [],
      "source": [
        "def remove_background(probs, labels, rects):\n",
        "    \"\"\"\n",
        "        Remove the background regions (boxes) and their probabilities to be able to feed them to the NMS algorithm\n",
        "        NMS only needs candidate boxes/regions and no background boxes\n",
        "    \"\"\"\n",
        "    new_labels = []\n",
        "    new_rects = []\n",
        "    new_probs = []\n",
        "    for x in np.unique(labels):\n",
        "          if x!= 43: # class 43 is the background\n",
        "              indexes = np.where(labels == x)[0]\n",
        "              for i in indexes:\n",
        "                  new_probs.append(probs[i])\n",
        "                  new_rects.append(rects[i].tolist())\n",
        "                  new_labels.append(x)\n",
        "    return new_probs, new_labels, new_rects\n",
        "\n",
        "\n",
        "def fill_output_dict(boxes, labels):\n",
        "    \"\"\"\n",
        "        Make the output as a dictionary so that each key is the class/label of the shild and the value is coordinates of the box(es)\n",
        "        Value can be multiple boxes per class because an image can have 2 shilds of the same type.\n",
        "    \"\"\"\n",
        "    output = {}\n",
        "    for x in np.unique(labels):\n",
        "        indexes = np.where(labels==x)[0]\n",
        "        output[x] = [boxes[i] for i in indexes]\n",
        "    return output\n",
        "\n",
        "def perform_nms_on_candidate_rectangles(probs, labels, rects, threshold=.5):\n",
        "    \"\"\"\n",
        "        Perform NMS on the boxes and get the ...\n",
        "    \"\"\"\n",
        "    probs, labels, rects = remove_background(probs, labels, rects)\n",
        "    rects = [convert_xywh_to_xxyy(x) for x in rects ]\n",
        "    D_index = NMS(rects, probs, threshold=threshold)\n",
        "    selected_boxes = [rects[i] for i in D_index]\n",
        "    selected_labels = [labels[i] for i in D_index]\n",
        "    output = fill_output_dict(selected_boxes, selected_labels)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiPrkgG5mjjB"
      },
      "outputs": [],
      "source": [
        "def convert_xywh_to_xxyy(rect):\n",
        "    startX, startY, width, height = rect\n",
        "    return startX, startY, (startX + width), (startY + height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9CqPJN1fkPZ"
      },
      "outputs": [],
      "source": [
        "def detect_shild(path, ratio=1., threshold=.5):\n",
        "    \"\"\"\n",
        "        This is the main function.\n",
        "        This performs:\n",
        "          - Read image\n",
        "          - Select regions\n",
        "          - Get mini images\n",
        "          - Feed mini images to model and get class-prob sets for each mini image\n",
        "          - Perform NMS on the regions and get final result\n",
        "    \"\"\"\n",
        "    img = read_img(path, ratio)\n",
        "    rects = create_selective_regions(img)\n",
        "    imgs = create_mini_images(img, rects)\n",
        "    (probs, labels) = prob_and_label_multiple_imgs(imgs)\n",
        "    output = perform_nms_on_candidate_rectangles(probs, labels, rects, threshold)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZ5FfncIEsU"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path=\"debug_image.png\"\n",
        "RATIO = .1\n",
        "THRESHOLD = .001\n",
        "output_rects = detect_shild(path=path, ratio=RATIO, threshold=THRESHOLD)\n",
        "\n",
        "output_rects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import base64\n",
        "\n",
        "def retangles(image_file_name):\n",
        "    try:\n",
        "        path = image_file_name\n",
        "        RATIO = 0.1\n",
        "        THRESHOLD = 0.001\n",
        "\n",
        "        #coordinates?\n",
        "        output_rects = detect_shild(path=path, ratio=RATIO, threshold=THRESHOLD)\n",
        "\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        img = read_img(path, ratio=RATIO)\n",
        "        ax.imshow(img)\n",
        "\n",
        "        for key in output_rects.keys():\n",
        "            c_rect = output_rects[key]\n",
        "            for x in c_rect:\n",
        "                rect = patches.Rectangle((x[0], x[1]), x[2] - x[0], x[3] - x[1], linewidth=1, edgecolor='r', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "                ax.text(x[0] + 3, x[1] - 5, key, color=\"r\")\n",
        "\n",
        "        ax.axis('off')\n",
        "\n",
        "        #plt.savefig('foo.png')\n",
        "\n",
        "        # Save the plot to a BytesIO object\n",
        "        buf = io.BytesIO()\n",
        "        fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
        "        buf.seek(0)\n",
        "        plt.close(fig)  # Close the figure to release resources\n",
        "        \n",
        "        # Encode the plot to a base64 string\n",
        "        img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
        "        buf.close()\n",
        "\n",
        "        keys = [int(key) for key in output_rects.keys()]\n",
        "        output_rects = {int(key): value for key, value in output_rects.items()}\n",
        "\n",
        "        return output_rects, img_base64  # Return the base64 string\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_file_name}: {repr(e)}\")\n",
        "        return None, None  # Return None indicating error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDjQ-C2LIGlZ"
      },
      "source": [
        "# MQTT Loop: Run this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu23nj2xm3aG",
        "outputId": "e3e25e82-a595-461c-b003-868e5eb9a85e"
      },
      "outputs": [],
      "source": [
        "import paho.mqtt.client as mqtt\n",
        "import base64\n",
        "import json\n",
        "import base64\n",
        "\n",
        "\n",
        "def on_connect(client, userdata, flags, rc):\n",
        "    print(\"Connected with result code \"+str(rc))\n",
        "    client.subscribe(\"adas/image\", 0) \n",
        "\n",
        "# The callback for when a PUBLISH message is received from the server.\n",
        "def on_message(mosq, obj, msg):\n",
        "    \n",
        "    try:\n",
        "      if msg.topic.startswith(\"adas/image\"):\n",
        "        json_message = msg.payload.decode('utf-8')\n",
        "\n",
        "        # Parse JSON\n",
        "        data = json.loads(json_message)\n",
        "\n",
        "        # the image comes in a  format of byte64 so we need to decode it first and then we can save it as .png\n",
        "        # Decode Base64 image data ->\n",
        "        image_base64 = data['image']\n",
        "        image_bytes = base64.b64decode(image_base64)\n",
        "\n",
        "        #save it as 'debug_image.png'\n",
        "        with open('debug_image.png', 'wb') as image_file:\n",
        "            image_file.write(image_bytes)\n",
        "\n",
        "        image_file_name = \"debug_image.png\"\n",
        "\n",
        "        #run the retangles function that returns the calssification photo as base64 and also the classes with coordinates\n",
        "        output_rects, img_base64 = retangles(image_file_name)\n",
        "\n",
        "        if img_base64:\n",
        "            # Create a JSON object\n",
        "            json_data = {\n",
        "                \"keys\": output_rects,\n",
        "                \"image\": img_base64\n",
        "            }\n",
        "\n",
        "            # Convert JSON object to string\n",
        "            json_string = json.dumps(json_data)\n",
        "\n",
        "            # Publish the JSON string\n",
        "            client.publish(\"adas/\", json_string)\n",
        "            print('Image processed and sent!')\n",
        "\n",
        "    except Exception as e:\n",
        "      print(\"Error processing the messages::\", repr(e))\n",
        "\n",
        "         \n",
        "      \n",
        "client = mqtt.Client()\n",
        "client.on_connect = on_connect\n",
        "client.on_message = on_message\n",
        "\n",
        "client.connect(\"broker.hivemq.com\", 1883, 60)\n",
        "client.loop_forever()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
